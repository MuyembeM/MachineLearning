{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuyembeM/MachineLearning/blob/main/DataSubsampler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "2BK6NDEvu1yP"
      },
      "cell_type": "code",
      "source": [
        "# dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "k2K610G-u1yU"
      },
      "cell_type": "code",
      "source": [
        "# fix the seed for better reproducibility\n",
        "SEED = 42\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "tW03BLhWu1yV"
      },
      "cell_type": "code",
      "source": [
        "# make tqdm work with pandas\n",
        "tqdm.pandas()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "mGeHF0Bdu1yW"
      },
      "cell_type": "code",
      "source": [
        "# load the dataset and preview\n",
        "data = pd.read_pickle('dataframe_extractive.pkl')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "kHoutwM7u1yW"
      },
      "cell_type": "code",
      "source": [
        "# story length distribution\n",
        "d1_sent_count = data.groupby('story_id').size().reset_index(name='count_sentences')\n",
        "d1_sent_count.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "DfISmQh2u1yX"
      },
      "cell_type": "code",
      "source": [
        "# median of the story lengths\n",
        "d1_sent_count['count_sentences'].median()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "3ha4uVHfu1yX"
      },
      "cell_type": "code",
      "source": [
        "# filter the stories that have a length < 30\n",
        "list_stories_subset = list(d1_sent_count[d1_sent_count['count_sentences'] < 30]['story_id'])\n",
        "len(list_stories_subset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ReGOM590u1yY"
      },
      "cell_type": "code",
      "source": [
        "# now subset 50000 stories\n",
        "SUBSET = 50000\n",
        "list_stories_subset = random.sample(list_stories_subset, SUBSET)\n",
        "len(np.unique(list_stories_subset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "IbhtCgqhu1yY"
      },
      "cell_type": "code",
      "source": [
        "# split training:validation:testing data 3:1:1\n",
        "train_ids = list_stories_subset[:30000]\n",
        "validation_ids = list_stories_subset[30000:40000]\n",
        "test_ids = list_stories_subset[40000:]\n",
        "\n",
        "train = data[data['story_id'].isin(train_ids)]\n",
        "valid = data[data['story_id'].isin(validation_ids)]\n",
        "test = data[data['story_id'].isin(test_ids)]\n",
        "\n",
        "train.shape, valid.shape, test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "U4yD75_Yu1yY"
      },
      "cell_type": "code",
      "source": [
        "# story length distribution plot in the training dataset\n",
        "train = train.sort_values(['story_id','sent_id'])\n",
        "d2_sent_count = train.groupby('story_id').size().reset_index(name='count_sentences')\n",
        "sns.displot(d2_sent_count['count_sentences'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "h6Su3GWuu1yZ"
      },
      "cell_type": "code",
      "source": [
        "# descriptive statistics of story length in the training dataset\n",
        "d2_sent_count['count_sentences'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "xIe6h_-Ru1yZ"
      },
      "cell_type": "code",
      "source": [
        "# note the maximum story length from the training dataset\n",
        "# to be used for preprocessing\n",
        "max_len_story = d2_sent_count['count_sentences'].max()\n",
        "max_len_story"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "oMqgmXyau1ya"
      },
      "cell_type": "code",
      "source": [
        "# total number of unique sentences in the training dataset\n",
        "sent_ls = set(train['sentence'].tolist())\n",
        "len(sent_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Qq7gH6hSu1ya"
      },
      "cell_type": "code",
      "source": [
        "# unique labels in the training dataset\n",
        "# 0: sentence is not a summary candidate\n",
        "# 1: sentence is a summary candidate\n",
        "tags = list(set(train['label_sent'].values))\n",
        "n_tags = len(tags)\n",
        "n_tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "9786oX8eu1yb"
      },
      "cell_type": "code",
      "source": [
        "# encoding the sentence labels and reversing them\n",
        "tag2idx  = {t: i + 1 for i, t in enumerate(tags)}\n",
        "tag2idx['PAD'] = 0\n",
        "idx2tag = {i: s for s, i in tag2idx.items()}\n",
        "print(tag2idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "PSFue8K6u1yb"
      },
      "cell_type": "code",
      "source": [
        "def add_word_lengths(df):\n",
        "    df['word_len'] = df['sentence'].progress_apply(lambda x: len(x.split()))\n",
        "    df['word_lis'] = df['sentence'].progress_apply(lambda x: x.split())\n",
        "    return df"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "7teDrU59u1yc"
      },
      "cell_type": "code",
      "source": [
        "train = add_word_lengths(train)\n",
        "valid = add_word_lengths(valid)\n",
        "test = add_word_lengths(test)\n",
        "\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "7LzFFv0ru1yc"
      },
      "cell_type": "code",
      "source": [
        "# sentence length distribution per story from the training dataset\n",
        "sns.displot(train['word_len'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "fdq7f0Wru1yc"
      },
      "cell_type": "code",
      "source": [
        "# descriptive statistics of sentence length distribution per story\n",
        "# from the training dataset\n",
        "train['word_len'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "RVNd4-IOu1yc"
      },
      "cell_type": "code",
      "source": [
        "# total number of unique words in our training corpus\n",
        "word_ls = set(list(chain(*train['word_lis'].tolist())))\n",
        "n_words = len(word_ls)\n",
        "print(n_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "xQ5me5yOu1yd"
      },
      "cell_type": "code",
      "source": [
        "# mapping the words to integers (tokenization) because machines don't\n",
        "# understand raw text\n",
        "word2idx = {c: i+2 for i,c in enumerate(word_ls)}\n",
        "word2idx['UNK'] = 1\n",
        "word2idx['PAD'] = 0\n",
        "\n",
        "# reversing this dictionary as this would be needed for post-processing\n",
        "idx2word = {i: s for s, i in word2idx.items()}"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "VXKso2i4u1yd"
      },
      "cell_type": "code",
      "source": [
        "def append_sent_labels(df):\n",
        "    df['sent_lab'] = df[['sentence','label_sent']].apply(tuple, axis=1)\n",
        "    return df"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "oulLJplHu1yd"
      },
      "cell_type": "code",
      "source": [
        "train = append_sent_labels(train)\n",
        "valid = append_sent_labels(valid)\n",
        "test = append_sent_labels(test)\n",
        "\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ZjCGatN0u1yd"
      },
      "cell_type": "code",
      "source": [
        "# sanity check the unique story ids in each of the splits\n",
        "train['story_id'].nunique(), valid['story_id'].nunique(), test['story_id'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "BD5GbXdWu1ye"
      },
      "cell_type": "code",
      "source": [
        "# we can play with this number but for now we will settle with 40\n",
        "MAX_LEN_WORD = 40\n",
        "\n",
        "def represent_stories(df):\n",
        "    # filter out the labels from the data subset\n",
        "    story_ids = df['story_id'].unique()\n",
        "    stories_labels = []\n",
        "    for s_id in tqdm(story_ids):\n",
        "        temp_story = []\n",
        "        # get all the sentences with respect to the givcen story id\n",
        "        temp_story = list(df[df['story_id'] == s_id]['sent_lab'])\n",
        "        stories_labels.append(temp_story)\n",
        "\n",
        "    # initialize an all-zeros array in the shape of\n",
        "    # (nb_stories, max_story_length, max_sentence_lenght)\n",
        "    X_word = np.zeros((len(stories_labels), max_len_story, MAX_LEN_WORD))\n",
        "\n",
        "    for idx, story in tqdm(enumerate(stories_labels)):\n",
        "        story_seq = []\n",
        "\n",
        "        # to give an upper bound on the maximum length of the word sequence for sentence\n",
        "        for i in range(max_len_story):\n",
        "            sent_seq = []\n",
        "\n",
        "            # to give an upper bound on the maximum length of words to consider\n",
        "            for j in range(MAX_LEN_WORD):\n",
        "                try:\n",
        "                    split_sent = story[i][0].split()\n",
        "                    sent_seq.append(word2idx.get(split_sent[j]))\n",
        "                except:\n",
        "                    # exception will be there when there will not be any sentence for the length\n",
        "                    # and will be padded 0\n",
        "                    sent_seq.append(word2idx.get('PAD'))\n",
        "            story_seq.append(sent_seq)\n",
        "\n",
        "        X_word[idx] = np.array(story_seq)\n",
        "\n",
        "    return (X_word, stories_labels)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "QdcIwJZ_u1ye"
      },
      "cell_type": "code",
      "source": [
        "# preprocess the training corpus\n",
        "X_train, stories_labels_train = represent_stories(train)\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "wJpjZZMGu1ye"
      },
      "cell_type": "code",
      "source": [
        "# preprocess the validation set\n",
        "X_valid, stories_labels_valid = represent_stories(valid)\n",
        "X_valid.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "vkIQ9xUVu1yf"
      },
      "cell_type": "code",
      "source": [
        "def prepare_labels(story_labels):\n",
        "    y = [[tag2idx[w[1]] for w in s] for s in story_labels]\n",
        "    y = pad_sequences(maxlen=max_len_story,\n",
        "                  sequences=y,\n",
        "                  value=tag2idx[\"PAD\"],\n",
        "                  padding='post',\n",
        "                  truncating='post')\n",
        "    y = y.reshape(-1, max_len_story, 1)\n",
        "\n",
        "    return y"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUYfD1sMu1yf",
        "outputId": "0a5d14d3-9dce-450f-dcdf-220670693f27"
      },
      "cell_type": "code",
      "source": [
        "# preprocess the train and validation labels\n",
        "train_labels = prepare_labels(stories_labels_train)\n",
        "valid_labels = prepare_labels(stories_labels_valid)\n",
        "\n",
        "train_labels.shape, valid_labels.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30000, 1, 1), (10000, 1, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "0KxkeGxNu1yf"
      },
      "cell_type": "code",
      "source": [
        "# retrieve the GloVe 100d embeddings\n",
        "!wget https://github.com/MuyembeM/MachineLearning/blob/main/downloads/glove.6B.100d.txt?raw=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "-2bpqPYPu1yg"
      },
      "cell_type": "code",
      "source": [
        "# using pre-trained word embeddings in the keras model\n",
        "def get_embedding_matrix(word_index, embedding_path, embedding_dim):\n",
        "    embedding_matrix_all = {}\n",
        "    with open(embedding_path) as f:\n",
        "        for line in f:  # every line contains word followed by the vector value\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embedding_matrix_all[word] = coefs\n",
        "\n",
        "    # prepare embedding matrix with just the words in our word_index dictionary\n",
        "    num_words = len(word_index)\n",
        "    embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embedding_matrix_all.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    return embedding_matrix"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_ttnLzhou1yg"
      },
      "cell_type": "code",
      "source": [
        "# construct the model\n",
        "EMBEDDING_PATH = 'glove.6B.100d.txt?raw=true'\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "def get_baseline_model():\n",
        "    word_in = Input(shape=(max_len_story, MAX_LEN_WORD,))\n",
        "\n",
        "    emb_word = TimeDistributed(\n",
        "        Embedding(input_dim=(n_words + 2),\n",
        "            output_dim=EMBEDDING_DIM,\n",
        "            input_length=MAX_LEN_WORD,\n",
        "            weights=[get_embedding_matrix(word2idx,\n",
        "                EMBEDDING_PATH, EMBEDDING_DIM)],\n",
        "            trainable=True\n",
        "        )\n",
        "    )(word_in)\n",
        "\n",
        "\n",
        "    conv_layer = TimeDistributed(Convolution1D(128, 3, activation='relu'))(emb_word)\n",
        "    conv_layer = TimeDistributed(GlobalAveragePooling1D())(conv_layer)\n",
        "    main_lstm = Bidirectional(LSTM(units=32, return_sequences=True))(conv_layer)\n",
        "    out = TimeDistributed(Dense(n_tags + 1, activation=\"softmax\"))(main_lstm)\n",
        "\n",
        "    model = Model([word_in], out)\n",
        "\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "91MDt52nu1yg"
      },
      "cell_type": "code",
      "source": [
        "# model summary\n",
        "model = get_baseline_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "yi33Ab4_u1yr"
      },
      "cell_type": "code",
      "source": [
        "# plot the model architecture\n",
        "tf.keras.utils.plot_model(model, 'model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install wandb\n",
        "!pip install wandb"
      ],
      "metadata": {
        "id": "PWeCLfW23wNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "1wA-uzcNu1ys"
      },
      "cell_type": "code",
      "source": [
        "# import wandb and authenticate it\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "SfWqynVeu1ys"
      },
      "cell_type": "code",
      "source": [
        "# set up an early stopping callback to prevent overfitting\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "xrScXb0Au1yt"
      },
      "cell_type": "code",
      "source": [
        "# initialize wandb\n",
        "wandb.init(entity='mkmuyembe', project='text-summarizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "0gvBcdsXu1yt"
      },
      "cell_type": "code",
      "source": [
        "# reinitialize, compile, and train the model\n",
        "model = get_baseline_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit([X_train],\n",
        "     train_labels,\n",
        "     validation_data=([X_valid], valid_labels),\n",
        "     batch_size=64,\n",
        "     epochs=10,\n",
        "     callbacks=[es, WandbCallback()],\n",
        "     verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "nNP9aHg_u1yt"
      },
      "cell_type": "code",
      "source": [
        "# serialize model for later use\n",
        "model.save('my_model.keras')"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "EMmM16Uyu1yu"
      },
      "cell_type": "code",
      "source": [
        "def represent_single_story(df, story_id):\n",
        "\tstories_labels = []\n",
        "\ttemp_story = []\n",
        "\n",
        "\t# get all the sentences with respect to the givcen story id\n",
        "\ttemp_story = list(df[df['story_id'] == story_id]['sent_lab'])\n",
        "\tstories_labels.append(temp_story)\n",
        "\n",
        "\t# initialize an all-zeros array in the shape of\n",
        "\t# (nb_stories, max_story_length, max_sentence_lenght)\n",
        "\tX_word = np.zeros((len(stories_labels), max_len_story, MAX_LEN_WORD))\n",
        "\n",
        "\tfor idx, story in tqdm(enumerate(stories_labels)):\n",
        "\t\tstory_seq = []\n",
        "\n",
        "\t\t# to give an upper bound on the maximum length of the word sequence for sentence\n",
        "\t\tfor i in range(max_len_story):\n",
        "\t\t\tsent_seq = []\n",
        "\n",
        "\t\t\t# to give an upper bound on the maximum length of words to consider\n",
        "\t\t\tfor j in range(MAX_LEN_WORD):\n",
        "\t\t\t\ttry:\n",
        "\t\t\t\t\tsplit_sent = story[i][0].split()\n",
        "\t\t\t\t\tsent_seq.append(word2idx.get(split_sent[j]))\n",
        "\t\t\t\texcept:\n",
        "\t\t\t\t\t# exception will be there when there will not be any sentence for the length\n",
        "\t\t\t\t\t# and will be padded 0\n",
        "\t\t\t\t\tsent_seq.append(word2idx.get('PAD'))\n",
        "\t\t\tstory_seq.append(sent_seq)\n",
        "\n",
        "\t\tX_word[idx] = np.array(story_seq)\n",
        "\n",
        "\treturn (X_word, stories_labels)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "gyYGpfesu1yu"
      },
      "cell_type": "code",
      "source": [
        "# get a random story id from the test set\n",
        "random_test_story_id = np.random.choice(np.unique(test['story_id'].tolist()), 1)[0]\n",
        "random_test_story_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "tXzjp-ucu1yu"
      },
      "cell_type": "code",
      "source": [
        "# preprocess the story\n",
        "X_word_test_single_story, story_labels_single = represent_single_story(test, random_test_story_id)\n",
        "X_word_test_single_story.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "r3aXWmHwu1yv"
      },
      "cell_type": "code",
      "source": [
        "# preprocess the labels associated with the story\n",
        "y_test_single = prepare_labels(story_labels_single)\n",
        "y_test_single.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "d_uB_bP4u1yv"
      },
      "cell_type": "code",
      "source": [
        "# run the model to predict on the preprocessed story and take an argmax\n",
        "# along the last dimension\n",
        "summary_predicted = model.predict(X_word_test_single_story).argmax(axis=-1)\n",
        "summary_predicted.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "C-bOf6Tbu1yw"
      },
      "cell_type": "code",
      "source": [
        "# let's manually see the predictions and compare them with the ground truth labels\n",
        "print(summary_predicted)\n",
        "print(y_test_single.squeeze(axis=-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "SW0wgmMfu1yx"
      },
      "cell_type": "code",
      "source": [
        "# get the index from prediction array where the value is 2\n",
        "# and use it to query the preprocessed test story\n",
        "idx = np.where(summary_predicted==2)\n",
        "summary_predicted = X_word_test_single_story[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "TNN53vifu1yx"
      },
      "cell_type": "code",
      "source": [
        "decoded_predictions = []\n",
        "\n",
        "# decode the predictions\n",
        "for i in range(len(summary_predicted)):\n",
        "    # get the sentence\n",
        "    sentence_encoded = summary_predicted[i]\n",
        "\n",
        "    # initialize an empty list to populate the decoded words with\n",
        "    sentence_deocded = [idx2word.get(idx) for idx in sentence_encoded if idx!=0 if idx2word.get(idx) is not None]\n",
        "\n",
        "    # prepare the sentence\n",
        "    sentence_deocded = ' '.join(sentence_deocded)\n",
        "\n",
        "    decoded_predictions.append(sentence_deocded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "3Rvifl6ku1yx"
      },
      "cell_type": "code",
      "source": [
        "# preview\n",
        "print(f'Predicted summaries of story id {random_test_story_id}')\n",
        "decoded_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "5KacrYVLu1yx"
      },
      "cell_type": "code",
      "source": [
        "# let's now see the original summary candidates\n",
        "print(f'Original summaries of story id {random_test_story_id}')\n",
        "test.query('story_id == @random_test_story_id & label_sent==1')['sentence'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "FFl7nKdtu1yy"
      },
      "cell_type": "code",
      "source": [
        "# first preprocess the entire test set\n",
        "X_test, stories_labels_test = represent_stories(test)\n",
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ZBy36oU1u1yy"
      },
      "cell_type": "code",
      "source": [
        "test_labels = prepare_labels(stories_labels_test)\n",
        "test_labels = test_labels.squeeze(-1) # to make it compatible for the evaluation metrics\n",
        "test_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "CzwD1meQu1yz"
      },
      "cell_type": "code",
      "source": [
        "# retrieve the predictions from all the test data points and take argmax along the last dimension\n",
        "test_predictions = model.predict(X_test).argmax(axis=-1)\n",
        "test_predictions.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "FUjIhcDYu1yz"
      },
      "cell_type": "code",
      "source": [
        "# evaluation metrics\n",
        "from sklearn.metrics import precision_score, recall_score , f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "K2cAF49Mu1yz"
      },
      "cell_type": "code",
      "source": [
        "f1_macro = []\n",
        "f1_micro = []\n",
        "f1_weight = []\n",
        "\n",
        "for i in tqdm(range(0, len(test_labels))) :\n",
        "\n",
        "    metric_macro = f1_score(test_labels[i], test_predictions[i], average='macro')\n",
        "    metric_micro = f1_score(test_labels[i], test_predictions[i], average='micro')\n",
        "    metric_weight = f1_score(test_labels[i], test_predictions[i], average='weighted')\n",
        "\n",
        "    f1_macro.append(metric_macro)\n",
        "    f1_micro.append(metric_micro)\n",
        "    f1_weight.append(metric_weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "-jlxt38vu1y0"
      },
      "cell_type": "code",
      "source": [
        "# create a dataframe from the numbers\n",
        "df_metric = pd.DataFrame()\n",
        "df_metric['f1_macro'] =  f1_macro\n",
        "df_metric['f1_micro'] =  f1_micro\n",
        "df_metric['f1_weight'] = f1_weight\n",
        "\n",
        "df_metric.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "YGyJaoBOu1y1"
      },
      "cell_type": "code",
      "source": [
        "train.to_csv('train.csv', index=False)\n",
        "valid.to_csv('valid.csv', index=False)\n",
        "test.to_csv('test.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "SnVHrTXWu1y1"
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(word2idx, open('word_dictionary.pkl', 'wb'))\n",
        "pickle.dump(idx2word, open('inverse_word_dictionary.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}